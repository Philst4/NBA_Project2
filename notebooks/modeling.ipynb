{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/processed/total.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop na's, duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select features to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features used:\n",
      "Index(['TEAM_WINS_prev_0_A', 'PTS_for_prev_0_A', 'PTS_against_prev_0_A',\n",
      "       'FG_PCT_for_prev_0_A', 'FG_PCT_against_prev_0_A',\n",
      "       'FG3_PCT_for_prev_0_A', 'FG3_PCT_against_prev_0_A', 'AST_for_prev_0_A',\n",
      "       'AST_against_prev_0_A', 'REB_for_prev_0_A',\n",
      "       ...\n",
      "       'PTS_against_prev_20_B', 'FG_PCT_for_prev_20_B',\n",
      "       'FG_PCT_against_prev_20_B', 'FG3_PCT_for_prev_20_B',\n",
      "       'FG3_PCT_against_prev_20_B', 'AST_for_prev_20_B',\n",
      "       'AST_against_prev_20_B', 'REB_for_prev_20_B', 'REB_against_prev_20_B',\n",
      "       'IS_HOME_B'],\n",
      "      dtype='object', length=134)\n"
     ]
    }
   ],
   "source": [
    "# Specifying which features are being used\n",
    "X_cols = [col for col in df.columns if \n",
    "             \"_0\" in col \n",
    "             or \"_1\" in col \n",
    "             or \"_3\" in col \n",
    "             or \"_5\" in col \n",
    "             or \"_10\" in col \n",
    "             or \"_20\" in col\n",
    "             or \"IS_HOME\" in col]\n",
    "print(\"Features used:\")\n",
    "\n",
    "X = df[X_cols].copy()\n",
    "print(X.columns)\n",
    "y = df[\"TEAM_WINS_A\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change data to np array or tensor, AFTER feature selection stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.values\n",
    "y = y.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split complete\n"
     ]
    }
   ],
   "source": [
    "# Splitting data into training and testing data\n",
    "X_train, X_test, y_train, y_true = train_test_split(X, y, test_size=0.2, random_state=2)\n",
    "print('Split complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define model, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained!\n",
      "Accuracy: 0.66\n"
     ]
    }
   ],
   "source": [
    "# Model training\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "lr_model.fit(X_train, y_train)\n",
    "print(\"Trained!\")\n",
    "\n",
    "# Get training accuracy\n",
    "print(\"Accuracy: {:.2f}\".format(1 - mean_absolute_error(lr_model.predict(X_train), y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY:\n",
      "0.6524565092716498\n"
     ]
    }
   ],
   "source": [
    "# Tests Logistic Regression Model\n",
    "y_pred = lr_model.predict(X_test)\n",
    "y_pred = y_pred.round()\n",
    "print(\"ACCURACY:\")\n",
    "print(1 - mean_absolute_error(y_pred, y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3414, 1840],\n",
       "       [1796, 3412]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows how often home team is predicted vs away team\n",
    "# TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test with torch model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redefine data as torch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = torch.from_numpy(X_train.astype(np.float32))\n",
    "y_tr= torch.from_numpy(y_train.astype(np.float32)).view(-1, 1)\n",
    "X_te = torch.from_numpy(X_test.astype(np.float32))\n",
    "y_te = torch.from_numpy(y_true.astype(np.float32)).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, 1)\n",
    "        \"\"\"self.linear2 = nn.Linear(input_size * 2, input_size * 2)\n",
    "        self.linear3 = nn.Linear(input_size * 2, 1)\"\"\"\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        \"\"\"out = self.linear2(out)\n",
    "        out = self.linear3(out)\"\"\"\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "\n",
    "# Instantiate the model\n",
    "input_size = X_tr.shape[1]\n",
    "model = LogisticRegressionModel(input_size)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()  # Binary Cross Entropy Loss\n",
    "optimizer = torch.optim.LBFGS(model.parameters(), lr=0.01, max_iter=100)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=0.3)  \n",
    "\n",
    "def closure():\n",
    "    optimizer.zero_grad()  # Zero the gradients to clear the previous values\n",
    "    y_pred = model(X_tr)  # Forward pass to compute predictions\n",
    "    loss = criterion(y_pred, y_tr)  # Compute the main loss\n",
    "\n",
    "    # Add L2 regularization (weight decay)\n",
    "    l2_lambda = 0.01  # Regularization strength (adjust as needed)\n",
    "    l2_reg = sum(p.pow(2.0).sum() for p in model.parameters())  # Compute L2 norm of model parameters\n",
    "    loss += l2_lambda * l2_reg  # Add L2 regularization term to the loss\n",
    "\n",
    "    loss.backward()  # Backward pass to compute gradients\n",
    "    return loss  # Return the total loss (including regularization term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/10], Loss: 0.6582\n",
      "Epoch [1/10], Loss: 0.6508\n",
      "Epoch [2/10], Loss: 0.6497\n",
      "Epoch [3/10], Loss: 0.6496\n",
      "Epoch [4/10], Loss: 0.6496\n",
      "Epoch [5/10], Loss: 0.6496\n",
      "Epoch [6/10], Loss: 0.6496\n",
      "Epoch [7/10], Loss: 0.6496\n",
      "Epoch [8/10], Loss: 0.6496\n",
      "Epoch [9/10], Loss: 0.6496\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    optimizer.step(closure)  # Update the model's parameters by one step\n",
    "\n",
    "    if True:\n",
    "        print(f'Epoch [{epoch}/{epochs}], Loss: {closure().item():.4f}')\n",
    "    lowest_loss = min(100, closure().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6356337220416747\n",
      "Lowest Loss: 0.6495757102966309\n"
     ]
    }
   ],
   "source": [
    "# Testing the model\n",
    "with torch.no_grad():\n",
    "    logit_pred = model(X_te)\n",
    "    y_pred = (y_pred >= 0.5).float()\n",
    "    \n",
    "    # Evaluate the accuracy\n",
    "    accuracy = accuracy_score(y_pred, y_true)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Lowest Loss:\", lowest_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TESTING RANDOM FOREST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6426113553813803\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "# Predict on the test set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRADIENT BOOSTING MACHINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6499713247944944\n"
     ]
    }
   ],
   "source": [
    "gb_classifier = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "gb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = gb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SUPPORT VECTOR MACHINES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_classifier = SVC(kernel='rbf', C=1.0, gamma='scale', probability=True, random_state=42)\n",
    "\n",
    "# Train the SVM classifier\n",
    "svm_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This SVC instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[134], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluation\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43msvm_classifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_true, y_pred)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/my_env/lib/python3.8/site-packages/sklearn/svm/_base.py:805\u001b[0m, in \u001b[0;36mBaseSVC.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    789\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Perform classification on samples in X.\u001b[39;00m\n\u001b[1;32m    790\u001b[0m \n\u001b[1;32m    791\u001b[0m \u001b[38;5;124;03m    For an one-class model, +1 or -1 is returned.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;124;03m        Class labels for samples in X.\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 805\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    806\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbreak_ties \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function_shape \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124movo\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbreak_ties must be False when decision_function_shape is \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124movo\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    809\u001b[0m         )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/my_env/lib/python3.8/site-packages/sklearn/utils/validation.py:1462\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1459\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not an estimator instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (estimator))\n\u001b[1;32m   1461\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[0;32m-> 1462\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This SVC instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
